---
title: "BES2019 Poster"

author:
- Gracielle T. Higino^1^, ^2^ \*, Marcos V. C. Vital^2^
- ^1^Department de Sciences Biologiques, Université de Montréal
- ^2^Programa de Pós-Graduação em Ecologia e Evolução, Universidade Federal de Goiás
- ^3^Departamento de Coisas Legais, Universidade Federal de Alagoas
- \*graciellehigino@gmail.com

date: "`r format(Sys.time(), '%d de %B de %Y')`"

knit: (function(inputFile, encoding) {
      out_dir <- 'manuscript';
      rmarkdown::render(inputFile,
                        encoding = encoding,
                        output_file = file.path(dirname(inputFile),
                        out_dir,
                        'manuscript.docx')) })
output:
  word_document:
    reference_docx: manuscript/sources/template.docx
csl: manuscript/sources/ecology-letters.csl
bibliography:
- manuscript/sources/library.bib
- manuscript/sources/installed-r-packages.bib
---



```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
# http://stackoverflow.com/questions/28894515/rmarkdown-directing-output-file-into-a-directory
out_dir <- 'manuscript'
if(!file.exists(out_dir)) {
  dir.create(out_dir)
}
```



```{r r_packages, include = FALSE}
# ipak function: install and load multiple R packages.
# Check to see if packages are installed.
# Install them if they are not, then load them into the R session.
# https://gist.github.com/stevenworthington/3178163

ipak <- function(pkg){
    new.pkg <- pkg[!(pkg %in% installed.packages()[, "Package"])]
    if (length(new.pkg))
    {
      install.packages(new.pkg,
                       dependencies = TRUE,
                       repos = "https://cloud.r-project.org")
    }
    suppressPackageStartupMessages(sapply(pkg, require, character.only = TRUE))
}

ipak(packages_list <- c(
                       "devtools",  # required; do not exclude from this list
                       "bibtex",    # required; do not exclude from this list
                       "knitr",     # required; do not exclude from this list
                       "rmarkdown", # required; do not exclude from this list
                       "pacman",    # required; do not exclude from this list
                       "captioner", # required; do not exclude from this list
                       "git2r",     # required; do not exclude from this list
                       "googlesheets4",
                       "CoordinateCleaner",
                       "curl",
                       "dplyr",
                       "doParallel",
                       "fs",
                       "future",
                       "furrr",
                       "here",
                       "rgbif",
                       "tidyr",
                       "parallel",
                       "purrr",
                       "taxize",
                       "tidylog",
                       "vroom"
                       )
     )

pacman::p_load_gh(char = c(
                           # required; do not exclude from this list
                           "benmarwick/wordcountaddin",
                           # required; do not exclude from this list
                           "ropensci/rcrossref"
                           ),
                  install = TRUE,
                  dependencies = TRUE)

write.bib(packages_list, "manuscript/sources/installed-r-packages.bib")

fig <- captioner(prefix ="Figure")
tab <- captioner(prefix="Table")
```

# Abstract

*BES*
Biases and gaps on biodiversity data can have serious consequences on ecological and conservation research and actions, as it can lead to misconstrued hypotheses and incorrect conclusions. Although there is still digital knowledge to be found and organized, recent efforts on gathering global biodiversity data, such as data papers, have revealed long hidden information. Nevertheless, it is of major importance to map and describe the biases on the data we have available. Here we assessed terrestrial vertebrates inventory incompleteness at the Atlantic Rainforest and investigate if environmental variables are correlated to biodiversity knowledge. Our results showed clusters of quality information near big conservation centres. Environmental variables that commonly indicates species richness were not correlated to inventory completeness, but when only well-sampled units were analysed, mammals’ rarefaction slopes were correlated with potential evapotranspiration. Underexplored regions need urgent investments in sampling efforts to assess its real biodiversity and efficiently measure environmental impacts.


**Keywords: biodiversity digital knowledge, wallacean shortfall, macroecology, **

##### page break

# Intro



##### page break

# Methods



##### page break

# Results

```{r importing data, echo=FALSE, warning=FALSE,message=FALSE,results='hide'}
c <- makeCluster(detectCores()-1)

# Read CSV with urls for all data
#devtools::install_github("tidyverse/googlesheets4")
#datasource <- googlesheets4::read_sheet("https://docs.google.com/spreadsheets/d/1qq6YTTcAIZVI9olRVgSm5sKVlxuS-4yW-yD06TXJzgg/edit?usp=sharing")

# geting zip files from Data Papers

if(file.exists("data/data.Rdata")){
  load("data/data.Rdata")
} else {

  gbif<-rgbif::occ_download_import(occ_download_get("0023533-180131172636756", path = "data/raw"), quote = "")
  
  # filenumbers <- 1:length(datasource$url)
  # filenames <- paste0("data/raw/file", filenumbers, ".zip")
  # 
  # for (i in 1:length(datasource$url)){
  #     files <-  list(download.file(datasource$url[i], filenames[i]))
  #     unzip(filenames[i], exdir = "/data/raw")
  #     }
  # rm(filenumbers, filenames, files)

  ## Amphibia - Datapapers
  amp_dp <- dplyr::inner_join(read.csv("data/raw/ATLANTIC_AMPHIBIANS_sites.csv"),
                  read.csv("data/raw/ATLANTIC_AMPHIBIANS_species.csv"), by = "id")
  
  ## Mammals
  # Bats
  bat_capture <- read.csv("data/raw/ATLANTIC_BATS_Capture.csv") # read data with species names
  cols <- strsplit(colnames(bat_capture), "[.]|[,]", fixed = FALSE) # creat column names vector to use on `separate`
  cols <-  cols[[1]][! cols[[1]] %in% ""]
  bat_capture <- tidyr::separate(bat_capture, 1, cols, sep = "[,]", remove = TRUE) # separate data in proper columns
  bat_sites <-  read.csv("data/raw/ATLANTIC_BATS_Study_site.csv") # read data with coordinates
  
  bat_dp <- dplyr::inner_join(bat_capture, bat_sites, by = "ID") # merge
  
  rm(cols, bat_capture, bat_sites)
  
  # Small Mammals
  mamsmall_dp <- dplyr::inner_join(read.csv("data/raw/ATLANTIC_SM_Study_Site.csv"),
                  read.csv("data/raw/ATLANTIC_SM_Capture.csv"), by = "ID.")
  
  # Camtraps Mammals
  loc <- read.csv("data/raw/ATLANTIC_CAMTRAPS_1-0_LOCATION.csv")
  survey <- read.csv("data/raw/ATLANTIC_CAMTRAPS_1-0_SURVEY.csv")
  records <- read.csv("data/raw/ATLANTIC_CAMTRAPS_1-0_RECORDS.csv")
  sp <- read.csv("data/raw/ATLANTIC_CAMTRAPS_1-0_SPECIES.csv")
  
  mamct_dp <- dplyr::inner_join(loc, survey, by = "location_id")
  mamct_dp <- dplyr::inner_join(mamct_dp, records, by = "survey_id")
  mamct_dp <- dplyr::inner_join(mamct_dp, sp, by = "species_id")
  
  rm(loc, survey, records, sp)
  
  # Primates
  mamprim_dp <-  read.csv("data/raw/Dataset/ATLANTIC-PR_Occurrence.csv", sep = ";")
  
  # Small mammals
  sites <- read.csv("data/raw/Mammals_UPRB_study_sites.csv")
  sp <- readr::read_csv("data/raw/Mammals_UPRB_species.csv")
  sp <- tidyr::pivot_longer(sp, dplyr::contains("ite_"), names_to = "site", values_to = "abundance", names_prefix = "site_")
  sp <- sp[sp$abundance != 0,]
  mamsmall2_dp <- dplyr::inner_join(sites, sp, by = "site")
  
  rm(sites,sp)
  
  
  ## Birds
  birds_dp <- read.csv("data/raw/DataS1/DataS1/ATLANTIC_BIRDS_qualitative.csv")
  
  # Data Dryad - for future us
  
  ## iDigBio
  # download.file("http://s.idigbio.org/idigbio-downloads/48532368-4e8e-4166-90f9-a4ee28002a4b.zip", "data/raw/idigbio.zip")
  # unzip("data/raw/idigbio.zip", exdir = "data/raw")
  idigbio <- read.csv("data/raw/occurrence_raw.csv")

  # Save everything
  save(gbif, amp_dp, bat_dp, mamsmall_dp, mamsmall2_dp, mamct_dp, mamprim_dp, birds_dp, idigbio, file ="data/raw/occ_data.Rdata")

}
```
```{r subseting datasets}
## Amphibia
amp <- amp_dp %>% select(latitude,longitude,species)
rm(amp_dp)


## Aves
ave <- birds_dp %>% select(Latitude_y,Longitude_x,Species)
colnames(ave) <- c("latitude", "longitude", "species")
rm(birds_dp)

## Mammals
subsetting <- function(dataset){
  select(dataset, contains("lat"), contains("long"), contains("sp"))
}
mam <- list(bat_dp,mamprim_dp,mamsmall_dp,mamsmall2_dp)
for (i in mam){
  mam <- lapply(mam, subsetting)
  rm(bat_dp,mamprim_dp,mamsmall_dp,mamsmall2_dp)
}

# Select only columns for lat, long and species name
mam[[2]] <- mam[[2]][,1:3]
mam[[3]] <- mam[[3]][,c(1,2,4)]
mam[[4]] <- mam[[4]][,c(1,2,4)]
mam[[5]] <- mamct_dp[,c(7,6,36)]
rm(mamct_dp)

# Standardazing colnames
for (i in 1:5) {
  colnames(mam[[i]]) <- c("latitude", "longitude", "species")
}

# Merging
mam <- bind_rows(mam)

## iDigBio
idigbio <- idigbio %>% 
    rename(
      latitude = dwc.decimalLatitude,
      longitude = dwc.decimalLongitude,
      class = dwc.classs,
      species = dwc.scientificName
    ) %>%
    select(class, species, latitude, longitude) %>%
    drop_na() %>% 
    group_by(species) %>%
    distinct(latitude, longitude, .keep_all = TRUE) %>%
    ungroup()

#TODO  ## Split iDigBio into classes
# Retrieving class from scientific name

  # Resolving sci. names
  # Data Sources IDs:
  # 173 = The Reptile Database
  # 3 = ITIS
  # 4 = NCBI
  # 11 = GBIF
  # 174 = Mammal Species of the World
  # 175 = BirdLife International
  
  #TODO split names and glue together only the actual words
  #redo grn_resolve and classification
  
  # idb_sp <- idigbio$species
  # idb_sp <- strsplit(as.character(idb_sp), split="[*\\ \\d ]")
  
  idb_spnames<-parLapply(c, as.character(idigbio$species), gnr_resolve,
                         data_source_ids=c(173,3,4,11,174,175),
                         resolve_once=FALSE,
                         with_context=FALSE,canonical=FALSE,highestscore=TRUE,
                         best_match_only=TRUE,http="post",splitby=50,cap_first=TRUE,
                         fields = "minimal")
 
  sp.val <- vector(length = length(idb_spnames))
  for (i in 1:length(idb_spnames)){
    if (length(idb_spnames[i][[1]]>0)){
      sp.val[i] <- idb_spnames[[i]]$matched_name
    }
  }
#NOTE 20191114 - saved idigbio, idb_spnames and sp.val in 'data/raw/idigbio.Rdata'. Load it next time.
#
#load("data/raw/idigbio.Rdata")

# TODO get classes of valid names
# body working, but time consuming
  
  !# Drop NA from sp.val before running classification
  
  # Getting classes of species
  classif <- parLapply(c, sp.val,
          classification, db="gbif", rows=1)
   
  classif <- flatten(classif)
  #%>% map(~ split(.$name, .$rank)) %>% transpose %>% map(flatten_chr)
  # # purrr::keep or discard()
  # 
  # purrr::flatten(head(classif)) %>% purrr::transpose(.)
  # 
  classes <- vector(length = length(classif))
  for (i in 1:length(classif)){
    if (is.na(names(classif[i]))){
      classes[i] <- "NA"
      } else {
        if (is.na(classif[[i]])) {
          classes[i] <- "NA"
          } else {
            if (length(filter(classif[[i]], rank=="class")$name)>0){
              classes[i] <- filter(classif[[i]], rank=="class")$name
              } else {
                classes[i] <- "NA"
              }
          }
      }
  }
  
  
  idigbio$class <- classes # replace class column with new variable
  #levels(as.factor(idigbio$class))
  idigbio <- idigbio[idigbio$class != c("Liliopsida", "FALSE", "NA"),]
  idigbio$class[idigbio$class=="Insecta"] <- "Reptilia"
  idigbio$class[idigbio$species=="Hylodes aspersa"] <- "Amphibia"
  
  idigbio_classes <- split(idigbio, idigbio$class) #split df into classes
  
  
  #TODO merge each element of the previous list with its corresponding data
  
## GBIF
# gbif <-
#   gbif %>% 
#     rename(
#       latitude = decimalLatitude,
#       longitude = decimalLongitude
#       class = dwc.class,
#       species = dwc.scientificName
#     ) %>%
#     select(class, species, latitude, longitude) %>%
#     group_by(species) %>%
#     distinct(latitude, longitude, .keep_all = TRUE) %>%
#     ungroup()
# 


```


##### page break

# Discussion


##### page break

# Conclusion

Lorem ipsum dolor sit amet, consectetur adipisicing elit, sed do eiusmod
tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam,
quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo
consequat. Duis aute irure dolor in reprehenderit [@Vellend2001] in voluptate velit esse
cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non
proident, sunt in culpa qui officia deserunt mollit anim id est laborum.

##### page break

# R packages

```{r eval = TRUE, echo = FALSE, results='asis'}
cite_pkg <- function(pkg_list) {

  packages <- sort(pkg_list)
  cites <- lapply(packages, utils::citation)
  cites.bib <- lapply(cites, utils::toBibtex)

  # generate reference key
  for (i in seq_len(length(cites.bib))) {
    cites.bib[[i]] <-
      sub(
        pattern = "\\{,$",
        replacement = paste0("{", packages[i], ","),
        x = cites.bib[[i]]
      )
  }

  # write bibtex references to file
  writeLines(enc2utf8(unlist(cites.bib)), con = "manuscript/sources/pkg-refs.bib", useBytes = TRUE)

  # return named list of bibtex references
  names(cites.bib) <- packages # pkgs

  writeLines(paste("- ", names(cites.bib), " [@", names(cites.bib), "]", sep = ""))
}


cite_pkg(packages_list)
```

##### page break

# References

<!-- https://stackoverflow.com/a/44294306/5974372 -->

<div id="refs"></div>

##### page break

# Tables

<!-- https://datascienceplus.com/r-markdown-how-to-number-and-reference-tables/ -->


```{r, eval=TRUE, echo=FALSE, results='asis'}
cat(tab(name = "tab_exemplo", "Apenas um exempĺo de como aplicar a legenda em uma tabela."))
knitr::kable(x = head(mtcars), format = "markdown", align = "c")
```

##### page break

# Figures

```{r, echo=FALSE, eval=TRUE, results='asis', fig.height=10, fig.width=10}
plot(1:10, pch = 21, bg = "red")
cat("\n", fig(name = "fig_exemplo", "Apenas um exemplo de como aplicar a legenda em um figura."))
```

##### page break

External figures can also be included using the `include_graphics` function. Example code below:

```{r, echo=TRUE, eval=FALSE}
include_graphics(path = "pasta/da/minha/figura", dpi = "2in")
```

##### page break

# Appendix

##### page break

Word count by *wordcountaddin* package

```{r, echo=TRUE, eval=TRUE, message=FALSE}
wordcountaddin::text_stats(filename = "main-script.Rmd")
```

##### page break

```{r session-info}
sessionInfo()
```
