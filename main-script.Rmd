---
title: "BES2019 Poster"

author:
- Gracielle T. Higino^1^, ^2^ \*, Marcos V. C. Vital^2^
- ^1^Department de Sciences Biologiques, Université de Montréal
- ^2^Programa de Pós-Graduação em Ecologia e Evolução, Universidade Federal de Goiás
- ^3^Departamento de Coisas Legais, Universidade Federal de Alagoas
- \*graciellehigino@gmail.com

date: "`r format(Sys.time(), '%d de %B de %Y')`"

knit: (function(inputFile, encoding) {
      out_dir <- 'manuscript';
      rmarkdown::render(inputFile,
                        encoding = encoding,
                        output_file = file.path(dirname(inputFile),
                        out_dir,
                        'manuscript.docx')) })
output:
  word_document:
    reference_docx: manuscript/sources/template.docx
csl: manuscript/sources/ecology-letters.csl
bibliography:
- manuscript/sources/library.bib
- manuscript/sources/installed-r-packages.bib
---



```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
# http://stackoverflow.com/questions/28894515/rmarkdown-directing-output-file-into-a-directory
out_dir <- 'manuscript'
if(!file.exists(out_dir)) {
  dir.create(out_dir)
}
```



```{r r_packages, include = FALSE}
# ipak function: install and load multiple R packages.
# Check to see if packages are installed.
# Install them if they are not, then load them into the R session.
# https://gist.github.com/stevenworthington/3178163

ipak <- function(pkg){
    new.pkg <- pkg[!(pkg %in% installed.packages()[, "Package"])]
    if (length(new.pkg))
    {
      install.packages(new.pkg,
                       dependencies = TRUE,
                       repos = "https://cloud.r-project.org")
    }
    suppressPackageStartupMessages(sapply(pkg, require, character.only = TRUE))
}

ipak(packages_list <- c(
                       "devtools",  # required; do not exclude from this list
                       "bibtex",    # required; do not exclude from this list
                       "knitr",     # required; do not exclude from this list
                       "rmarkdown", # required; do not exclude from this list
                       "pacman",    # required; do not exclude from this list
                       "captioner", # required; do not exclude from this list
                       "git2r",     # required; do not exclude from this list
                       "googlesheets4",
                       "biogeo",    # optional; check again after geographic processing
                       "CoordinateCleaner",
                       "curl",
                       "dismo",
                       "dplyr",
                       "doParallel",
                       "fs",
                       "future",
                       "furrr",
                       "here",
                       "mapdata",
                       "maps",
                       "maptools",
                       "rgbif",
                       "rgeos",
                       "tidyr",
                       "parallel",
                       "purrr",
                       "raster",
                       "rgdal",
                       "sp",
                       "sqldf",
                       "taxize",
                       "tm",
                       "tidylog",
                       "vegan",
                       "vroom"
                       )
     )

pacman::p_load_gh(char = c(
                           # required; do not exclude from this list
                           "benmarwick/wordcountaddin",
                           # required; do not exclude from this list
                           "ropensci/rcrossref"
                           ),
                  install = TRUE,
                  dependencies = TRUE)

write.bib(packages_list, "manuscript/sources/installed-r-packages.bib")

fig <- captioner(prefix ="Figure")
tab <- captioner(prefix="Table")
```

# Abstract

*BES*
Biases and gaps on biodiversity data can have serious consequences on ecological and conservation research and actions, as it can lead to misconstrued hypotheses and incorrect conclusions. Although there is still digital knowledge to be found and organized, recent efforts on gathering global biodiversity data, such as data papers, have revealed long hidden information. Nevertheless, it is of major importance to map and describe the biases on the data we have available. Here we assessed terrestrial vertebrates inventory incompleteness at the Atlantic Rainforest and investigate if environmental variables are correlated to biodiversity knowledge. Our results showed clusters of quality information near big conservation centres. Environmental variables that commonly indicates species richness were not correlated to inventory completeness, but when only well-sampled units were analysed, mammals’ rarefaction slopes were correlated with potential evapotranspiration. Underexplored regions need urgent investments in sampling efforts to assess its real biodiversity and efficiently measure environmental impacts.


**Keywords: biodiversity digital knowledge, wallacean shortfall, macroecology, **

##### page break

# Intro



##### page break

# Methods



##### page break

# Results

```{r importing data, echo=FALSE, warning=FALSE,message=FALSE,results='hide'}
c <- makeCluster(detectCores()-1)

# Read CSV with urls for all data
#devtools::install_github("tidyverse/googlesheets4")
#datasource <- googlesheets4::read_sheet("https://docs.google.com/spreadsheets/d/1qq6YTTcAIZVI9olRVgSm5sKVlxuS-4yW-yD06TXJzgg/edit?usp=sharing")

# geting zip files from Data Papers

if(file.exists("data/data.Rdata")){
  load("data/data.Rdata")
} else {

  gbif<-occ_download_import(occ_download_get("0023533-180131172636756", path = "data/raw", overwrite = TRUE), quote = "")

  # filenumbers <- 1:length(datasource$url)
  # filenames <- paste0("data/raw/file", filenumbers, ".zip")
  #
  # for (i in 1:length(datasource$url)){
  #     files <-  list(download.file(datasource$url[i], filenames[i]))
  #     unzip(filenames[i], exdir = "/data/raw")
  #     }
  # rm(filenumbers, filenames, files)

  ## Amphibia - Datapapers
  amp_dp <- dplyr::inner_join(read.csv("data/raw/ATLANTIC_AMPHIBIANS_sites.csv"),
                  read.csv("data/raw/ATLANTIC_AMPHIBIANS_species.csv"), by = "id")

  ## Mammals
  # Bats
  bat_capture <- read.csv("data/raw/ATLANTIC_BATS_Capture.csv") # read data with species names
  cols <- strsplit(colnames(bat_capture), "[.]|[,]", fixed = FALSE) # creat column names vector to use on `separate`
  cols <-  cols[[1]][! cols[[1]] %in% ""]
  bat_capture <- tidyr::separate(bat_capture, 1, cols, sep = "[,]", remove = TRUE) # separate data in proper columns
  bat_sites <-  read.csv("data/raw/ATLANTIC_BATS_Study_site.csv") # read data with coordinates

  bat_dp <- dplyr::inner_join(bat_capture, bat_sites, by = "ID") # merge

  rm(cols, bat_capture, bat_sites)

  # Small Mammals
  mamsmall_dp <- dplyr::inner_join(read.csv("data/raw/ATLANTIC_SM_Study_Site.csv"),
                  read.csv("data/raw/ATLANTIC_SM_Capture.csv"), by = "ID.")

  # Camtraps Mammals
  loc <- read.csv("data/raw/ATLANTIC_CAMTRAPS_1-0_LOCATION.csv")
  survey <- read.csv("data/raw/ATLANTIC_CAMTRAPS_1-0_SURVEY.csv")
  records <- read.csv("data/raw/ATLANTIC_CAMTRAPS_1-0_RECORDS.csv")
  sp <- read.csv("data/raw/ATLANTIC_CAMTRAPS_1-0_SPECIES.csv")

  mamct_dp <- dplyr::inner_join(loc, survey, by = "location_id")
  mamct_dp <- dplyr::inner_join(mamct_dp, records, by = "survey_id")
  mamct_dp <- dplyr::inner_join(mamct_dp, sp, by = "species_id")

  rm(loc, survey, records, sp)

  # Primates
  mamprim_dp <-  read.csv("data/raw/Dataset/ATLANTIC-PR_Occurrence.csv", sep = ";")

  # Small mammals
  sites <- read.csv("data/raw/Mammals_UPRB_study_sites.csv")
  sp <- readr::read_csv("data/raw/Mammals_UPRB_species.csv")
  sp <- tidyr::pivot_longer(sp, dplyr::contains("ite_"), names_to = "site", values_to = "abundance", names_prefix = "site_")
  sp <- sp[sp$abundance != 0,]
  mamsmall2_dp <- dplyr::inner_join(sites, sp, by = "site")

  rm(sites,sp)


  ## Birds
  birds_dp <- read.csv("data/raw/DataS1/DataS1/ATLANTIC_BIRDS_qualitative.csv")

  # Data Dryad - for future us

  ## iDigBio
  # download.file("http://s.idigbio.org/idigbio-downloads/48532368-4e8e-4166-90f9-a4ee28002a4b.zip", "data/raw/idigbio.zip")
  # unzip("data/raw/idigbio.zip", exdir = "data/raw")
  idigbio <- read.csv("data/raw/occurrence_raw.csv")

}
```
```{r subseting datasets}
## Amphibia
amp <- amp_dp %>% select(latitude,longitude,species)
rm(amp_dp)


## Aves
ave <- birds_dp %>% select(Latitude_y,Longitude_x,Species)
colnames(ave) <- c("latitude", "longitude", "species")
rm(birds_dp)

## Mammals
subsetting <- function(dataset){
  select(dataset, contains("lat"), contains("long"), contains("sp"))
}
mam <- list(bat_dp,mamprim_dp,mamsmall_dp,mamsmall2_dp)
for (i in mam){
  mam <- lapply(mam, subsetting)
  rm(bat_dp,mamprim_dp,mamsmall_dp,mamsmall2_dp)
}

# Select only columns for lat, long and species name
mam[[2]] <- mam[[2]][,1:3]
mam[[3]] <- mam[[3]][,c(1,2,4)]
mam[[4]] <- mam[[4]][,c(1,2,4)]
mam[[5]] <- mamct_dp[,c(7,6,36)]
rm(mamct_dp)

# Standardazing colnames
for (i in 1:5) {
  colnames(mam[[i]]) <- c("latitude", "longitude", "species")
}

# Merging
mam <- bind_rows(mam)

## iDigBio
idigbio <- idigbio %>%
    rename(
      latitude = dwc.decimalLatitude,
      longitude = dwc.decimalLongitude,
      class = dwc.classs,
      species = dwc.scientificName
    ) %>%
    select(class, species, latitude, longitude) %>%
    drop_na() %>%
    group_by(species) %>%
    distinct(latitude, longitude, .keep_all = TRUE) %>%
    ungroup()

  # Resolving sci. names
  # Data Sources IDs:
  # 173 = The Reptile Database
  # 3 = ITIS
  # 4 = NCBI
  # 11 = GBIF
  # 174 = Mammal Species of the World
  # 175 = BirdLife International

  idb_spnames<-parLapply(c, as.character(idigbio$species), gnr_resolve,
                         data_source_ids=c(173,3,4,11,174,175),
                         resolve_once=FALSE,
                         with_context=FALSE,canonical=FALSE,highestscore=TRUE,
                         best_match_only=TRUE,http="post",splitby=50,cap_first=TRUE,
                         fields = "minimal")

  sp.val <- vector(length = length(idb_spnames))
  for (i in 1:length(idb_spnames)){
    if (length(idb_spnames[i][[1]]>0)){
      sp.val[i] <- idb_spnames[[i]]$matched_name
    }
  }

  !# For the future: drop NA from sp.val before running classification

  # Getting classes of species
  classif <- parLapply(c, sp.val,
          classification, db="gbif", rows=1)

  classes = as.data.frame(matrix(NA, length(classif),1))
  names(classes) = "Class"
  for (i in 1:length(classif)) {
    if(!is.na(names(classif[[i]])) & !is.na(classif[[i]])) {
      class = unname(classif[[i]])[[1]] %>% filter(rank == "class")
       if(nrow(class) != 0) {
         classes[i,] = class %>% select("name")
       }
    }
  }


  idigbio$class <- classes$Class # replace class column with new variable
  #levels(idigbio$class)
  idigbio <- filter(idigbio, class %in% c("Aves", "Amphibia", "Mammalia", "Reptilia")) # Exclude occurrences due to misclassification and invalid names

  idigbio_classes <- split(idigbio, idigbio$class)
  list2env(idigbio_classes, .GlobalEnv) #split df into classes


  aves <- rbind(ave, Aves[2:4])
  amp <- rbind(amp, Amphibia[2:4])
  mam <- rbind(mam, Mammalia[2:4])
  rep <- Reptilia
  rm(ave, Aves, Amphibia, Mammalia, Reptilia)


# GBIF
gbif <-
  gbif %>%
    rename(
      latitude = decimalLatitude,
      longitude = decimalLongitude,
      sp = scientificName
    ) %>%
    select(class, sp, latitude, longitude) %>%
    drop_na() %>%
    group_by(sp) %>%
    distinct(latitude, longitude, .keep_all = TRUE) %>%
    ungroup()
rename(gbif, species = sp)

gbif_classes <- split(gbif, gbif$class)
list2env(gbif_classes, .GlobalEnv)


  aves <- rbind(aves, Aves[2:4])
  amp <- rbind(amp, Amphibia[2:4])
  mam <- rbind(mam, Mammalia[2:4])
  rep <- rbind(rep[2:4], Reptilia[2:4])
  rm(Aves, Amphibia, Mammalia, Reptilia)

```
```{r geographic subset}
# Get shapefile from here: https://c402277.ssl.cf1.rackcdn.com/publications/15/files/original/official_teow.zip?1349272619
# unzip(curl::curl_download("https://c402277.ssl.cf1.rackcdn.com/publications/15/files/original/official_teow.zip?1349272619", destfile = "data/raw/ecoregion.zip"), exdir = "data/raw")

  ma<-readOGR("data/raw/official/wwf_terr_ecos.shp")
  ma<-ma[ma$G200_REGIO %in% c("Atlantic Forests", "Atlantic dry Forests"),]


# Subset occurrences that are inside ma shp

  ## check for NAs and drop them
  amp <- na.exclude(amp)
  aves <- na.exclude(aves)
  mam <- na.exclude(mam)
  rep <- na.exclude(rep)

  ## Set coordinates

  groups <- list(amp, aves, mam, rep)
  ovr <- list(length(groups))
  rm(amp, aves, mam, rep)
  names(groups) <- c("amp", "aves", "mam", "rep")
  for (i in 1:4) {
    coordinates(groups[[i]]) <- ~longitude+latitude
    crs(groups[[i]]) <- crs(ma)
    ovr[[i]] <- over(groups[[i]],ma)
    groups[[i]] <- cbind(groups[[i]]@coords, groups[[i]]@data, ovr[[i]])
    groups[[i]] <- groups[[i]][!is.na(groups[[i]]$G200_REGIO),]
  }
  list2env(groups, .GlobalEnv)
  rm(groups)
```
```{r final sp names checking}
c <- makeCluster(detectCores()-1)

# Amphibia

amp.spnames<-parLapply(c, as.character(amp$species), gnr_resolve,
                         data_source_ids=c(173,3,4,11,174,175),
                         resolve_once=FALSE,
                         with_context=FALSE,canonical=FALSE,highestscore=TRUE,
                         best_match_only=TRUE,http="post",splitby=50,cap_first=TRUE,
                         fields = "minimal")



  amp.spnames.val <- vector(length = length(amp.spnames))
  for (i in 1:length(amp.spnames)){
    if (length(amp.spnames[i][[1]]>0)){
      amp.spnames.val[i] <- amp.spnames[[i]]$matched_name
    }
  }
  amp <- amp[amp$species %in% amp.spnames.val,]
  rm(amp.spnames, amp.spnames.val)

# Aves
aves.spnames<-parLapply(c, as.character(aves$species), gnr_resolve,
                         data_source_ids=c(173,3,4,11,174,175),
                         resolve_once=FALSE,
                         with_context=FALSE,canonical=FALSE,highestscore=TRUE,
                         best_match_only=TRUE,http="post",splitby=50,cap_first=TRUE,
                         fields = "minimal")

  aves.spnames.val <- vector(length = length(aves.spnames))
  for (i in 1:length(aves.spnames)){
    if (length(aves.spnames[i][[1]]>0)){
      aves.spnames.val[i] <- aves.spnames[[i]]$matched_name
    }
  }
  aves <- aves[aves$species %in% aves.spnames.val,]
  rm(aves.spnames, aves.spnames.val)


# Mammalia
mam.spnames<-parLapply(c, as.character(mam$species), gnr_resolve,
                         data_source_ids=c(173,3,4,11,174,175),
                         resolve_once=FALSE,
                         with_context=FALSE,canonical=FALSE,highestscore=TRUE,
                         best_match_only=TRUE,http="post",splitby=50,cap_first=TRUE,
                         fields = "minimal")

  mam.spnames.val <- vector(length = length(mam.spnames))
  for (i in 1:length(mam.spnames)){
    if (length(mam.spnames[i][[1]]>0)){
      mam.spnames.val[i] <- mam.spnames[[i]]$matched_name
    }
  }
  mam <- mam[mam$species %in% mam.spnames.val,]
  rm(mam.spnames, mam.spnames.val)

# Reptilia
rep.spnames<-parLapply(c, as.character(rep$species), gnr_resolve,
                         data_source_ids=c(173,3,4,11,174,175),
                         resolve_once=FALSE,
                         with_context=FALSE,canonical=FALSE,highestscore=TRUE,
                         best_match_only=TRUE,http="post",splitby=50,cap_first=TRUE,
                         fields = "minimal")

  rep.spnames.val <- vector(length = length(rep.spnames))
  for (i in 1:length(rep.spnames)){
    if (length(rep.spnames[i][[1]]>0)){
      rep.spnames.val[i] <- rep.spnames[[i]]$matched_name
    }
  }
  rep <- rep[rep$species %in% rep.spnames.val,]
  rm(rep.spnames,rep.spnames.val)

```

```{r env rasters}
# Download data
## NDVI -
download.file("https://neo.sci.gsfc.nasa.gov/servlet/RenderData?si=1780053&cs=gs&format=TIFF&width=3600&height=1800", mode="wb", destfile = "data/raw/ndvi.tiff")
ndvi <- raster("data/raw/ndvi.tiff")
  # Set equal resolutions and extentions
  ndvi <- disaggregate(ndvi, fact=12)
  # Crop
  ndvi <- crop(ndvi, extent(ma))

## PET -  Trabucco, Antonio; Zomer, Robert (2019): Global Aridity Index and Potential Evapotranspiration (ET0) Climate Database v2. figshare. Fileset. https://doi.org/10.6084/m9.figshare.7504448.v3

download.file("https://ndownloader.figshare.com/files/14118800", mode ="wb",destfile = "data/raw/pet.zip")
unzip("data/raw/pet.zip", exdir = "data/raw")
pet <- raster("data/raw/ai_et0/ai_et0.tif")
pet <- crop(pet, extent(ma))

## Temperature - WorldClim (bioclim 01)
temper1 <- getData(name = 'worldclim', var='bio', download = TRUE, path = "data/raw",
                   lat = -25, lon = -60, res=0.5)[[1]]
temper2 <- getData(name = 'worldclim', var='bio', download = TRUE, path = "data/raw",
                   lat = -60, lon = -60, res=0.5)[[1]]
temper <- mosaic(temper1, temper2, fun=mean)
rm(temper1, temper2)
temper <- crop(temper, extent(ma))

## Topography - WorldClim
topog <-  getData(name = 'alt', country="Brazil", download = TRUE, path = "data/raw",mask=FALSE)
topog <- crop(topog, extent(ma))



# Get values for each cell and build df of environmental variable

ind <- rbind(amp[1:2], aves[1:2], mam[1:2], rep[1:2])
cells<-cellFromXY(pet, ind) # Get occurrence cells from raster

## Get variables from raster
temp.p<-raster::extract(temper,ind, "simple")
topog.p<-raster::extract(topog,ind, "simple")
ndvi.p<-raster::extract(ndvi, ind, "simple")
pet.p<-raster::extract(pet, ind,"simple")

## Build dfs
### environmental variables
env <- cbind(cells, ind, temp.p, topog.p, ndvi.p, pet.p)
colnames(env) <- c("cells", "longitude", "latitude", "temperature", "topography", "ndvi", "pet")

### occurrences
occ <- bind_rows("amp" = amp[1:3], "rep" = rep[1:3], .id="class")
```
```{r species richness for AR}
# Slope of the species accumulation curve
occ$abundance<-1
occ$abundance<-as.integer(occ$abundance)
occ$cells <- cells
tt<-sqldf("select cells, count(species) as N_rec from occ group by cells having count(species) > 0")
df<-merge(x=occ, y=tt, by="cells", all.y=TRUE)
df<-df[, c(1, 4, 6)]
mat<-spaa::data2mat(df)

# From Stropp et al.:
  spaccum <- specaccum(mat, method = "exact")  
  total.slope <- (spaccum[[4]][length(spaccum[[4]])]-spaccum[[4]][ceiling(length(spaccum[[4]])*0.9)])/(length(spaccum[[4]])-ceiling(length(spaccum[[4]])*0.9))
  save(spaccum, total.slope, file="BES2019_poster/output/results/total_accum.Rdata")

plot(spaccum,add=FALSE,random=FALSE,ci=2,ci.type="polygon",col=par("fg"),ci.col="grey",xlim=c(1,170),
ci.lty=1,ylab="exact",xvar="sites")
text(round(total.slope,digits=3), x=160, y=50,pos=3)
text("Slope = ", x=143, y=50,pos=3)

# Species richness by cell
sr<-sqldf("select cells, count (distinct(species)) as sr_total from occ group by cells")
```


##### page break

# Discussion


##### page break

# Conclusion

Lorem ipsum dolor sit amet, consectetur adipisicing elit, sed do eiusmod
tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam,
quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo
consequat. Duis aute irure dolor in reprehenderit [@Vellend2001] in voluptate velit esse
cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non
proident, sunt in culpa qui officia deserunt mollit anim id est laborum.

##### page break

# R packages

```{r eval = TRUE, echo = FALSE, results='asis'}
cite_pkg <- function(pkg_list) {

  packages <- sort(pkg_list)
  cites <- lapply(packages, utils::citation)
  cites.bib <- lapply(cites, utils::toBibtex)

  # generate reference key
  for (i in seq_len(length(cites.bib))) {
    cites.bib[[i]] <-
      sub(
        pattern = "\\{,$",
        replacement = paste0("{", packages[i], ","),
        x = cites.bib[[i]]
      )
  }

  # write bibtex references to file
  writeLines(enc2utf8(unlist(cites.bib)), con = "manuscript/sources/pkg-refs.bib", useBytes = TRUE)

  # return named list of bibtex references
  names(cites.bib) <- packages # pkgs

  writeLines(paste("- ", names(cites.bib), " [@", names(cites.bib), "]", sep = ""))
}


cite_pkg(packages_list)
```

##### page break

# References

<!-- https://stackoverflow.com/a/44294306/5974372 -->

<div id="refs"></div>

##### page break

# Tables

<!-- https://datascienceplus.com/r-markdown-how-to-number-and-reference-tables/ -->


```{r, eval=TRUE, echo=FALSE, results='asis'}
cat(tab(name = "tab_exemplo", "Apenas um exempĺo de como aplicar a legenda em uma tabela."))
knitr::kable(x = head(mtcars), format = "markdown", align = "c")
```

##### page break

# Figures

```{r, echo=FALSE, eval=TRUE, results='asis', fig.height=10, fig.width=10}
plot(1:10, pch = 21, bg = "red")
cat("\n", fig(name = "fig_exemplo", "Apenas um exemplo de como aplicar a legenda em um figura."))
```

##### page break

External figures can also be included using the `include_graphics` function. Example code below:

```{r, echo=TRUE, eval=FALSE}
include_graphics(path = "pasta/da/minha/figura", dpi = "2in")
```

##### page break

# Appendix

##### page break

Word count by *wordcountaddin* package

```{r, echo=TRUE, eval=TRUE, message=FALSE}
wordcountaddin::text_stats(filename = "main-script.Rmd")
```

##### page break

```{r session-info}
sessionInfo()
```
